{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import io\n",
    "import os\n",
    "import datetime\n",
    "import json\n",
    "import time\n",
    "\n",
    "import gc\n",
    "import sys\n",
    "from types import ModuleType, FunctionType\n",
    "from gc import get_referents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Num CPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num CPUs Available: \", len(tf.config.experimental.list_physical_devices('CPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=15**3\n",
    "m_n = np.random.random((size,size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: mean=0.53908371925354, std=0.0\n"
     ]
    }
   ],
   "source": [
    "cpu_times = []\n",
    "with tf.device('/CPU:0'):\n",
    "    m_tf = tf.constant(m_n)\n",
    "    for i in range(10):\n",
    "        start = time.time()\n",
    "        result = tf.matmul(m_tf, m_tf)\n",
    "        end = time.time()\n",
    "\n",
    "    exec_time = end-start\n",
    "    cpu_times.append(exec_time)\n",
    "\n",
    "cpu_time_mean = np.mean(cpu_times)\n",
    "cpu_time_std = np.std(cpu_times)\n",
    "\n",
    "print(f\"CPU: mean={cpu_time_mean}, std={cpu_time_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: mean=4.315376281738281e-05, std=0.0\n"
     ]
    }
   ],
   "source": [
    "gpu_times = []\n",
    "with tf.device('/GPU:0'):\n",
    "    m_tf = tf.constant(m_n)\n",
    "    for i in range(10):\n",
    "        start = time.time()\n",
    "        result = tf.matmul(m_tf, m_tf)\n",
    "        end = time.time()\n",
    "    \n",
    "    exec_time = end-start\n",
    "    gpu_times.append(exec_time)\n",
    "\n",
    "gpu_time_mean = np.mean(gpu_times)\n",
    "gpu_time_std = np.std(gpu_times)\n",
    "\n",
    "print(f\"GPU: mean={gpu_time_mean}, std={gpu_time_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy: mean=0.3982331991195679, std=0.0644165405084919\n"
     ]
    }
   ],
   "source": [
    "numpy_times = []\n",
    "for i in range(10):\n",
    "\n",
    "    start = time.time()\n",
    "    result = np.matmul(m_n, m_n)\n",
    "    end = time.time()\n",
    "    \n",
    "    exec_time = end-start\n",
    "    numpy_times.append(exec_time)\n",
    "\n",
    "numpy_time_mean = np.mean(numpy_times)\n",
    "numpy_time_std = np.std(numpy_times)\n",
    "\n",
    "print(f\"NumPy: mean={numpy_time_mean}, std={numpy_time_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow GPU to Tensorflow CPU speedup: x12492\n"
     ]
    }
   ],
   "source": [
    "speedup = cpu_time_mean/gpu_time_mean\n",
    "print(f\"Tensorflow GPU to Tensorflow CPU speedup: x{speedup:.0f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cpu_speedup = 1\n",
    "numpy_speedup = cpu_time_mean/numpy_time_mean\n",
    "gpu_speedup = cpu_time_mean/gpu_time_mean\n",
    "\n",
    "data = {'speedups':[cpu_speedup, numpy_speedup, gpu_speedup],\n",
    "       'method':['CPU', 'NumPy', 'GPU']}\n",
    "\n",
    "ax = sns.barplot(x='method', y='speedups', data=data, palette=sns.cubehelix_palette(3, start=.9, rot=-.10))\n",
    "\n",
    "ax.set_title(\"Relative speedup\")\n",
    "\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del m_n\n",
    "del m_tf\n",
    "del result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3390"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset with subwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:TFDS datasets with text encoding are deprecated and will be removed in a future version. Instead, you should use the plain text version and tokenize the text using `tensorflow_text` (See: https://www.tensorflow.org/tutorials/tensorflow_text/intro#tfdata_example)\n"
     ]
    }
   ],
   "source": [
    "imdb_dataset, info = tfds.load('imdb_reviews/subwords8k',\n",
    "                         split=['train', 'test[:50%]', 'test[50%:]'],\n",
    "                         as_supervised=True,\n",
    "                         with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<PrefetchDataset shapes: ((None,), ()), types: (tf.int64, tf.int64)>, <PrefetchDataset shapes: ((None,), ()), types: (tf.int64, tf.int64)>, <PrefetchDataset shapes: ((None,), ()), types: (tf.int64, tf.int64)>]\n"
     ]
    }
   ],
   "source": [
    "print(imdb_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = imdb_dataset[0]\n",
    "valid_dataset = imdb_dataset[1]\n",
    "test_dataset = imdb_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='imdb_reviews',\n",
       "    version=1.0.0,\n",
       "    description='Large Movie Review Dataset.\n",
       "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.',\n",
       "    homepage='http://ai.stanford.edu/~amaas/data/sentiment/',\n",
       "    features=FeaturesDict({\n",
       "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
       "        'text': Text(shape=(None,), dtype=tf.int64, encoder=<SubwordTextEncoder vocab_size=8185>),\n",
       "    }),\n",
       "    total_num_examples=100000,\n",
       "    splits={\n",
       "        'test': 25000,\n",
       "        'train': 25000,\n",
       "        'unsupervised': 50000,\n",
       "    },\n",
       "    supervised_keys=('text', 'label'),\n",
       "    citation=\"\"\"@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
       "      author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
       "      title     = {Learning Word Vectors for Sentiment Analysis},\n",
       "      booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
       "      month     = {June},\n",
       "      year      = {2011},\n",
       "      address   = {Portland, Oregon, USA},\n",
       "      publisher = {Association for Computational Linguistics},\n",
       "      pages     = {142--150},\n",
       "      url       = {http://www.aclweb.org/anthology/P11-1015}\n",
       "    }\"\"\",\n",
       "    redistribution_info=,\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = info.features['text'].encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_dataset = tfds.load('imdb_reviews', split=['train', 'test[:50%]', 'test[50%:]'], as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = imdb_dataset[0]\n",
    "val_ds = imdb_dataset[1]\n",
    "test_ds = imdb_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ds size: 25000\n",
      "val_ds size: 12500\n",
      "test_ds size: 12500\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DS_SIZE = train_ds.cardinality().numpy()\n",
    "VAL_DS_SIZE = val_ds.cardinality().numpy()\n",
    "TEST_DS_SIZE = test_ds.cardinality().numpy()\n",
    "\n",
    "print(f\"train_ds size: {TRAIN_DS_SIZE}\")\n",
    "print(f\"val_ds size: {VAL_DS_SIZE}\")\n",
    "print(f\"test_ds size: {TEST_DS_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization and encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First approach: Keras Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_texts_and_labels(ds):\n",
    "    ds_length = ds.cardinality().numpy()\n",
    "    \n",
    "    # Convert from tf.data.Dataset to list\n",
    "    ds = next(ds.batch(ds_length).as_numpy_iterator())\n",
    "    \n",
    "    # Get lists\n",
    "    texts, labels = list(ds[0]), list(ds[1])\n",
    "    \n",
    "    # Convert from b string to utf-8 string\n",
    "    texts = list(map(lambda b_string: b_string.decode('utf-8'), texts))\n",
    "    \n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.86 s, sys: 686 ms, total: 2.55 s\n",
      "Wall time: 1.68 s\n",
      "CPU times: user 847 ms, sys: 298 ms, total: 1.15 s\n",
      "Wall time: 386 ms\n",
      "CPU times: user 787 ms, sys: 356 ms, total: 1.14 s\n",
      "Wall time: 334 ms\n"
     ]
    }
   ],
   "source": [
    "%time train_texts, train_y = dataset_to_texts_and_labels(train_ds)\n",
    "%time valid_texts, valid_y = dataset_to_texts_and_labels(val_ds)\n",
    "%time test_texts, test_y = dataset_to_texts_and_labels(test_ds)\n",
    "\n",
    "all_texts = train_texts + valid_texts + test_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.19 s, sys: 14.6 ms, total: 7.21 s\n",
      "Wall time: 7.21 s\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='<oov>')\n",
    "%time tokenizer.fit_on_texts(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.26 s, sys: 21.4 ms, total: 2.28 s\n",
      "Wall time: 2.28 s\n",
      "CPU times: user 1.11 s, sys: 2.57 ms, total: 1.11 s\n",
      "Wall time: 1.11 s\n",
      "CPU times: user 1.11 s, sys: 14.5 ms, total: 1.12 s\n",
      "Wall time: 1.12 s\n"
     ]
    }
   ],
   "source": [
    "%time train_x = tokenizer.texts_to_sequences(train_texts)\n",
    "%time valid_x = tokenizer.texts_to_sequences(valid_texts)\n",
    "%time test_x = tokenizer.texts_to_sequences(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(lambda: iter(zip(train_x, train_y)),\n",
    "                                               output_types=(tf.int32, tf.int32),\n",
    "                                               output_shapes=(tf.TensorShape([None]), tf.TensorShape([]))).take(TRAIN_DS_SIZE)\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: iter(zip(valid_x, valid_y)),\n",
    "                                               output_types=(tf.int32, tf.int32),\n",
    "                                               output_shapes=(tf.TensorShape([None]), tf.TensorShape([]))).take(VAL_DS_SIZE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(lambda: iter(zip(test_x, test_y)),\n",
    "                                              output_types=(tf.int32, tf.int32),\n",
    "                                              output_shapes=(tf.TensorShape([None]), tf.TensorShape([]))).take(TEST_DS_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(163,), dtype=int64, numpy=\n",
       " array([  62,   18,   41,  604,  927,   65,    3,  644, 7968,   21,   35,\n",
       "        5096,   36,   11,   43, 2948, 5240,  102,   50,  681, 7862, 1244,\n",
       "           3, 3266,   29,  122,  640,    2,   26,   14,  279,  438,   35,\n",
       "          79,  349,  384,   11, 1991,    3,  492,   79,  122,  188,  117,\n",
       "          33, 4047, 4531,   14,   65, 7968,    8, 1819, 3947,    3,   62,\n",
       "          27,    9,   41,  577, 5044, 2629, 2552, 7193, 7961, 3642,    3,\n",
       "          19,  107, 3903,  225,   85,  198,   72,    1, 1512,  738, 2347,\n",
       "         102, 6245,    8,   85,  308,   79, 6936, 7961,   23, 4981, 8044,\n",
       "           3, 6429, 7961, 1141, 1335, 1848, 4848,   55, 3601, 4217, 8050,\n",
       "           2,    5,   59, 3831, 1484, 8040, 7974,  174, 5773,   22, 5240,\n",
       "         102,   18,  247,   26,    4, 3903, 1612, 3902,  291,   11,    4,\n",
       "          27,   13,   18, 4092, 4008, 7961,    6,  119,  213, 2774,    3,\n",
       "          12,  258, 2306,   13,   91,   29,  171,   52,  229,    2, 1245,\n",
       "        5790,  995, 7968,    8,   52, 2948, 5240, 8039, 7968,    8,   74,\n",
       "        1249,    3,   12,  117, 2438, 1369,  192,   39, 7975])>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second approach: tfds Tokenizer and Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# tokenizer = tfds.features.text.Tokenizer()\n",
    "# vocabulary = set()\n",
    "# for dataset in [train_ds, val_ds, test_ds]:\n",
    "#     for batch in dataset:\n",
    "#         for x,y in batch:\n",
    "#             vocabulary.update(tokenizer.tokenize(x.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = tfds.features.text.TokenTextEncoder(vocabulary)\n",
    "# def encode(x, y):\n",
    "#     x = encoder.encode(x.numpy())\n",
    "#     return x, y\n",
    "\n",
    "# def encode_map_fn(x, y):\n",
    "#     x, y = tf.py_function(encode,\n",
    "#                          inp=[x, y],\n",
    "#                          Tout=(tf.int64, tf.int64))\n",
    "#     x.set_shape([None])\n",
    "#     y.set_shape([])\n",
    "#     return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time train_dataset = train_ds.map(encode_map_fn)\n",
    "# %time valid_dataset = val_ds.map(encode_map_fn)\n",
    "# %time test_dataset = test_ds.map(encode_map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MakeIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op IteratorGetNext in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op DeleteIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(117,), dtype=int32, numpy=\n",
       " array([   12,    14,    33,   420,   382,    18,    90,    27, 11312,\n",
       "            9,    32,  1460,  4087,    39,   499, 10040,   196,    24,\n",
       "           79,   151,    19,    12,   207,   331,    27,    66,   247,\n",
       "          215,     9,   485,    58,    66,    79,   114,    99,    22,\n",
       "         5800,    12,  1381,   647,   774,    12,    18,     7,    33,\n",
       "          405,  9016,   177,  2328,   413,     2,    89,  1152,   135,\n",
       "           71,   144,    51,     2, 35686,  6553,    71,   233,    66,\n",
       "         3097,    16, 20563,  3150, 24417, 22710,  1531,  4680,     3,\n",
       "           41,  3805,   113,  1505,    17,  4087,    14,   162,    19,\n",
       "            4,  1152,   888,  9017,     9,     4,    18,    13,    14,\n",
       "         3855,     5,   100,   145,  1159,    11,   236,   681,    13,\n",
       "           47,    24,    98,    38,    12,  8162,  5238,    38,  1460,\n",
       "        16388,    50,   390,    11,    99,  1184,   847,   141,    10],\n",
       "       dtype=int32)>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LEN = 300\n",
    "\n",
    "def pad_or_truncate(x, y):\n",
    "    length = SEQUENCE_LEN\n",
    "    x = x[:length]\n",
    "    if x.shape[0] < length:\n",
    "        x = tf.concat([x, tf.zeros(length-x.shape[0], dtype=tf.int32)], axis=0)\n",
    "    return x, y\n",
    "\n",
    "def pad_or_truncate_map_fn(x, y):\n",
    "    x, y = tf.py_function(pad_or_truncate, inp=[x, y], Tout=(tf.int32, tf.int32))\n",
    "    x.set_shape([SEQUENCE_LEN])\n",
    "    y.set_shape([])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_dataset = train_dataset.cache().shuffle(1024).padded_batch(batch_size=BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.cache().padded_batch(batch_size=BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.cache().padded_batch(batch_size=BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# BATCH_SIZE = 32\n",
    "# train_dataset = train_dataset.cache().shuffle(1024).map(pad_or_truncate_map_fn).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "# valid_dataset = valid_dataset.cache().map(pad_or_truncate_map_fn).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "# test_dataset = test_dataset.cache().map(pad_or_truncate_map_fn).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# BATCH_SIZE = 32\n",
    "# train_dataset = train_dataset.shuffle(1024).map(pad_or_truncate_map_fn).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "# valid_dataset = valid_dataset.map(pad_or_truncate_map_fn).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "# test_dataset = test_dataset.map(pad_or_truncate_map_fn).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare embedding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -O embeddings.zip http://vectors.nlpl.eu/repository/20/8.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip embeddings.zip\n",
    "# !rm embeddings.zip\n",
    "# !rm model.bin\n",
    "# !rm README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('meta.json') as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.getcwd(), 'model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = list(map(float, tokens[1:]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.2 s, sys: 1.48 s, total: 19.6 s\n",
      "Wall time: 20.2 s\n"
     ]
    }
   ],
   "source": [
    "%time word_vectors = load_vectors(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create embedding matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras tokenizer compatible approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_tokenizer_embedding_matrix(tokenizer, word_vectors):\n",
    "    n = len(tokenizer.index_word)+1\n",
    "    d = len(list(word_vectors.values())[0])\n",
    "    embedding_matrix = np.zeros((n,d))\n",
    "    for i, word in tokenizer.index_word.items():\n",
    "        vector = word_vectors.get(word, np.zeros(d))\n",
    "        embedding_matrix[i] = vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 755 ms, sys: 64.1 ms, total: 819 ms\n",
      "Wall time: 817 ms\n"
     ]
    }
   ],
   "source": [
    "%time embedding_matrix = keras_tokenizer_embedding_matrix(tokenizer, word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124254, 300)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Custom objects know their class.\n",
    "# Function objects seem to know way too much, including modules.\n",
    "# Exclude modules as well.\n",
    "BLACKLIST = type, ModuleType, FunctionType\n",
    "\n",
    "\n",
    "def getsize(obj):\n",
    "    \"\"\"sum size of object & members.\"\"\"\n",
    "    if isinstance(obj, BLACKLIST):\n",
    "        raise TypeError('getsize() does not take argument of type: '+ str(type(obj)))\n",
    "    seen_ids = set()\n",
    "    size = 0\n",
    "    objects = [obj]\n",
    "    while objects:\n",
    "        need_referents = []\n",
    "        for obj in objects:\n",
    "            if not isinstance(obj, BLACKLIST) and id(obj) not in seen_ids:\n",
    "                seen_ids.add(id(obj))\n",
    "                size += sys.getsizeof(obj)\n",
    "                need_referents.append(obj)\n",
    "        objects = get_referents(*need_referents)\n",
    "    return size/1024**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_vec_size = getsize(word_vectors)\n",
    "# emb_m_size = getsize(embedding_matrix)\n",
    "# print(f\"word_vectors size: {word_vec_size:10.0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To free memory\n",
    "del word_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tfds tokenizer and encoder compatible approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tfds_embedding_matrix(vocabulary, encoder, word_vectors):\n",
    "#     n = len(list(word_vectors.keys()))\n",
    "#     d = len(list(word_vectors.values())[0])\n",
    "#     embedding_matrix = np.zeros((n,d))\n",
    "#     for word in vocabulary:\n",
    "#         i = encoder.encode(word)[0]\n",
    "#         vector = word_vectors.get(word, np.zeros(d))\n",
    "#         embedding_matrix[i] = vector\n",
    "#     return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time embedding_matrix = tfds_embedding_matrix(vocabulary, encoder, word_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(32, 850), dtype=int64, numpy=\n",
       " array([[  69,   18, 1010, ...,    0,    0,    0],\n",
       "        [  62,   27,  579, ...,    0,    0,    0],\n",
       "        [2509, 4422, 7961, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 592, 3192,  792, ...,    0,    0,    0],\n",
       "        [  12,   31,  247, ...,    0,    0,    0],\n",
       "        [  12,  264,   33, ...,    0,    0,    0]])>,\n",
       " <tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0])>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 128)         1047680   \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, None, 128)         98816     \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, None, 128)         98816     \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, None, 128)         98816     \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 256)               263168    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,739,137\n",
      "Trainable params: 1,739,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "do_rate = 0.1 #0\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(None,)),\n",
    "    tf.keras.layers.Embedding(encoder.vocab_size, 128,\n",
    "#                               embeddings_initializer=tf.keras.initializers.constant(embedding_matrix),\n",
    "#                               trainable=False\n",
    "                             ),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(do_rate),\n",
    "#     tf.keras.layers.Dense(512, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(do_rate),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "#               optimizer=tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save embedding layer as model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_model = tf.keras.Sequential([model.layers[0]])\n",
    "# embedding_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_model.save(os.path.join(os.getcwd(), \"embedding_model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(os.getcwd(), \"logs/fit/\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0, update_freq='epoch')\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(os.path.join(os.getcwd(), 'model'),\n",
    "                                                               save_freq='epoch', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jan/ml_own_projects/text_data_projects/imdb_reviews/logs/fit/'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  1/391 [..............................] - ETA: 0s - loss: 0.6929 - accuracy: 0.5938WARNING:tensorflow:From /home/jan/.local/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jan/.local/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 173s 442ms/step - loss: 0.5594 - accuracy: 0.6918 - val_loss: 0.4408 - val_accuracy: 0.8046\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 171s 437ms/step - loss: 0.3536 - accuracy: 0.8551 - val_loss: 0.3792 - val_accuracy: 0.8370\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 172s 440ms/step - loss: 0.2642 - accuracy: 0.8986 - val_loss: 0.3573 - val_accuracy: 0.8549\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 169s 432ms/step - loss: 0.2335 - accuracy: 0.9147 - val_loss: 0.3717 - val_accuracy: 0.8582\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 171s 437ms/step - loss: 0.1909 - accuracy: 0.9328 - val_loss: 0.4108 - val_accuracy: 0.8482\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 170s 436ms/step - loss: 0.1749 - accuracy: 0.9389 - val_loss: 0.4383 - val_accuracy: 0.8522\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 170s 435ms/step - loss: 0.1520 - accuracy: 0.9480 - val_loss: 0.4763 - val_accuracy: 0.8496\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 175s 446ms/step - loss: 0.1274 - accuracy: 0.9588 - val_loss: 0.5036 - val_accuracy: 0.8468\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 173s 443ms/step - loss: 0.1462 - accuracy: 0.9496 - val_loss: 0.5240 - val_accuracy: 0.8316\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 171s 438ms/step - loss: 0.1059 - accuracy: 0.9648 - val_loss: 0.6352 - val_accuracy: 0.8335\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    validation_data=valid_dataset,\n",
    "                    epochs=10,\n",
    "                    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-48c4098b6e103bd3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-48c4098b6e103bd3\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir $log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
